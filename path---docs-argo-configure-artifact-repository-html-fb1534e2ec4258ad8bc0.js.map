{"version":3,"sources":["webpack:///path---docs-argo-configure-artifact-repository-html-fb1534e2ec4258ad8bc0.js","webpack:///./.cache/json/docs-argo-configure-artifact-repository-html.json"],"names":["webpackJsonp","471","module","exports","pathContext","docHtml","docPath","proj"],"mappings":"AAAAA,cAAc,gBAERC,IACA,SAAUC,EAAQC,GCHxBD,EAAAC,SAAkBC,aAAeC,QAAA,o/gBAAw4cC,QAAA,qCAAAC,KAAA","file":"path---docs-argo-configure-artifact-repository-html-fb1534e2ec4258ad8bc0.js","sourcesContent":["webpackJsonp([5458225705137],{\n\n/***/ 471:\n/***/ (function(module, exports) {\n\n\tmodule.exports = {\"pathContext\":{\"docHtml\":\"<h1 id=\\\"configuring-your-artifact-repository\\\"><a href=\\\"#configuring-your-artifact-repository\\\" aria-hidden=\\\"true\\\" class=\\\"anchor\\\"><svg aria-hidden=\\\"true\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg></a>Configuring Your Artifact Repository</h1>\\n<p>To run Argo workflows that use artifacts, you must configure and use an artifact\\nrepository. Argo supports any S3 compatible artifact repository such as AWS, GCS\\nand Minio. This section shows how to configure the artifact repository.\\nSubsequent sections will show how to use it.</p>\\n<h2 id=\\\"configuring-minio\\\"><a href=\\\"#configuring-minio\\\" aria-hidden=\\\"true\\\" class=\\\"anchor\\\"><svg aria-hidden=\\\"true\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg></a>Configuring Minio</h2>\\n<pre><code>$ brew install helm # mac, helm 3.x\\n$ helm repo add stable https://kubernetes-charts.storage.googleapis.com/ # official Helm stable charts\\n$ helm repo update\\n$ helm install argo-artifacts stable/minio --set service.type=LoadBalancer --set fullnameOverride=argo-artifacts\\n</code></pre>\\n<p>Login to the Minio UI using a web browser (port 9000) after obtaining the\\nexternal IP using <code>kubectl</code>.</p>\\n<pre><code>$ kubectl get service argo-artifacts\\n</code></pre>\\n<p>On Minikube:</p>\\n<pre><code>$ minikube service --url argo-artifacts\\n</code></pre>\\n<p>NOTE: When minio is installed via Helm, it uses the following hard-wired default\\ncredentials, which you will use to login to the UI:</p>\\n<ul>\\n<li>AccessKey: AKIAIOSFODNN7EXAMPLE</li>\\n<li>SecretKey: wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY</li>\\n</ul>\\n<p>Create a bucket named <code>my-bucket</code> from the Minio UI.</p>\\n<h2 id=\\\"configuring-aws-s3\\\"><a href=\\\"#configuring-aws-s3\\\" aria-hidden=\\\"true\\\" class=\\\"anchor\\\"><svg aria-hidden=\\\"true\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg></a>Configuring AWS S3</h2>\\n<p>Create your bucket and access keys for the bucket. AWS access keys have the same\\npermissions as the user they are associated with. In particular, you cannot\\ncreate access keys with reduced scope. If you want to limit the permissions for\\nan access key, you will need to create a user with just the permissions you want\\nto associate with the access key. Otherwise, you can just create an access key\\nusing your existing user account.</p>\\n<pre><code>$ export mybucket=bucket249\\n$ cat > policy.json &#x3C;&#x3C;EOF\\n{\\n   \\\"Version\\\":\\\"2012-10-17\\\",\\n   \\\"Statement\\\":[\\n      {\\n         \\\"Effect\\\":\\\"Allow\\\",\\n         \\\"Action\\\":[\\n            \\\"s3:PutObject\\\",\\n            \\\"s3:GetObject\\\"\\n         ],\\n         \\\"Resource\\\":\\\"arn:aws:s3:::$mybucket/*\\\"\\n      }\\n   ]\\n}\\nEOF\\n$ aws s3 mb s3://$mybucket [--region xxx]\\n$ aws iam create-user --user-name $mybucket-user\\n$ aws iam put-user-policy --user-name $mybucket-user --policy-name $mybucket-policy --policy-document file://policy.json\\n$ aws iam create-access-key --user-name $mybucket-user > access-key.json\\n</code></pre>\\n<p>NOTE: if you want argo to figure out which region your buckets belong in, you\\nmust additionally set the following statement policy. Otherwise, you must\\nspecify a bucket region in your workflow configuration.</p>\\n<pre><code>    ...\\n      {\\n         \\\"Effect\\\":\\\"Allow\\\",\\n         \\\"Action\\\":[\\n            \\\"s3:GetBucketLocation\\\"\\n         ],\\n         \\\"Resource\\\":\\\"arn:aws:s3:::*\\\"\\n      }\\n    ...\\n</code></pre>\\n<h2 id=\\\"configuring-gcs-google-cloud-storage\\\"><a href=\\\"#configuring-gcs-google-cloud-storage\\\" aria-hidden=\\\"true\\\" class=\\\"anchor\\\"><svg aria-hidden=\\\"true\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg></a>Configuring GCS (Google Cloud Storage)</h2>\\n<p>Create a bucket from the GCP Console\\n(<a href=\\\"https://console.cloud.google.com/storage/browser\\\">https://console.cloud.google.com/storage/browser</a>).</p>\\n<p>There are 2 ways to configure a Google Cloud Storage.</p>\\n<h3 id=\\\"through-native-gcs-apis\\\"><a href=\\\"#through-native-gcs-apis\\\" aria-hidden=\\\"true\\\" class=\\\"anchor\\\"><svg aria-hidden=\\\"true\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg></a>Through Native GCS APIs</h3>\\n<ul>\\n<li>Create and download a Google Cloud service account key.</li>\\n<li>Create a kubernetes secret to store the key.</li>\\n<li>Configure <code>gcs</code> artifact as following in the yaml.</li>\\n</ul>\\n<pre><code class=\\\"language-yaml\\\">artifacts:\\n  - name: message\\n    path: /tmp/message\\n    gcs:\\n      bucket: my-bucket-name\\n      key: path/in/bucket\\n      # serviceAccountKeySecret is a secret selector.\\n      # It references the k8s secret named 'my-gcs-credentials'.\\n      # This secret is expected to have have the key 'serviceAccountKey',\\n      # containing the base64 encoded credentials\\n      # to the bucket.\\n      #\\n      # If it's running on GKE and Workload Identity is used,\\n      # serviceAccountKeySecret is not needed.\\n      serviceAccountKeySecret:\\n        name: my-gcs-credentials\\n        key: serviceAccountKey\\n</code></pre>\\n<p>If it's a GKE cluster, and Workload Identity is configured, there's no need to\\ncreate the Service Account key and store it as a K8s secret,\\n<code>serviceAccountKeySecret</code> is also not needed in this case. Please follow the\\nlink to configure Workload Identity\\n(<a href=\\\"https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity\\\">https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity</a>).</p>\\n<h3 id=\\\"use-s3-apis\\\"><a href=\\\"#use-s3-apis\\\" aria-hidden=\\\"true\\\" class=\\\"anchor\\\"><svg aria-hidden=\\\"true\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg></a>Use S3 APIs</h3>\\n<p>Enable S3 compatible access and create an access key. Note that S3 compatible\\naccess is on a per project rather than per bucket basis.</p>\\n<ul>\\n<li>Navigate to Storage > Settings\\n(<a href=\\\"https://console.cloud.google.com/storage/settings\\\">https://console.cloud.google.com/storage/settings</a>).</li>\\n<li>Enable interoperability access if needed.</li>\\n<li>Create a new key if needed.</li>\\n<li>Confiture <code>s3</code> artifact as following exmaple.</li>\\n</ul>\\n<pre><code class=\\\"language-yaml\\\">artifacts:\\n  - name: my-output-artifact\\n    path: /my-ouput-artifact\\n    s3:\\n      endpoint: storage.googleapis.com\\n      bucket: my-gcs-bucket-name\\n      # NOTE that all output artifacts are automatically tarred and\\n      # gzipped before saving. So as a best practice, .tgz or .tar.gz\\n      # should be incorporated into the key name so the resulting file\\n      # has an accurate file extension.\\n      key: path/in/bucket/my-output-artifact.tgz\\n      accessKeySecret:\\n        name: my-gcs-s3-credentials\\n        key: accessKey\\n      secretKeySecret:\\n        name: my-gcs-s3-credentials\\n        key: secretKey\\n</code></pre>\\n<h1 id=\\\"configure-the-default-artifact-repository\\\"><a href=\\\"#configure-the-default-artifact-repository\\\" aria-hidden=\\\"true\\\" class=\\\"anchor\\\"><svg aria-hidden=\\\"true\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg></a>Configure the Default Artifact Repository</h1>\\n<p>In order for Argo to use your artifact repository, you can configure it as the\\ndefault repository. Edit the workflow-controller config map with the correct\\nendpoint and access/secret keys for your repository.</p>\\n<h2 id=\\\"s3-compatible-artifact-repository-bucket-such-as-aws-gcs-and-minio\\\"><a href=\\\"#s3-compatible-artifact-repository-bucket-such-as-aws-gcs-and-minio\\\" aria-hidden=\\\"true\\\" class=\\\"anchor\\\"><svg aria-hidden=\\\"true\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg></a>S3 compatible artifact repository bucket (such as AWS, GCS and Minio)</h2>\\n<p>Use the <code>endpoint</code> corresponding to your S3 provider:</p>\\n<ul>\\n<li>AWS: s3.amazonaws.com</li>\\n<li>GCS: storage.googleapis.com</li>\\n<li>Minio: my-minio-endpoint.default:9000</li>\\n</ul>\\n<p>The <code>key</code> is name of the object in the <code>bucket</code> The <code>accessKeySecret</code> and\\n<code>secretKeySecret</code> are secret selectors that reference the specified kubernetes\\nsecret. The secret is expected to have the keys 'accessKey' and 'secretKey',\\ncontaining the base64 encoded credentials to the bucket.</p>\\n<p>For AWS, the <code>accessKeySecret</code> and <code>secretKeySecret</code> correspond to\\nAWS<em>ACCESS</em>KEY<em>ID and AWS</em>SECRET<em>ACCESS</em>KEY respectively.</p>\\n<p>EC2 provides a metadata API via which applications using the AWS SDK may assume\\nIAM roles associated with the instance. If you are running argo on EC2 and the\\ninstance role allows access to your S3 bucket, you can configure the workflow\\nstep pods to assume the role. To do so, simply omit the <code>accessKeySecret</code> and\\n<code>secretKeySecret</code> fields.</p>\\n<p>For GCS, the <code>accessKeySecret</code> and <code>secretKeySecret</code> for S3 compatible access\\ncan be obtained from the GCP Console. Note that S3 compatible access is on a per\\nproject rather than per bucket basis.</p>\\n<ul>\\n<li>Navigate to Storage > Settings\\n(<a href=\\\"https://console.cloud.google.com/storage/settings\\\">https://console.cloud.google.com/storage/settings</a>).</li>\\n<li>Enable interoperability access if needed.</li>\\n<li>Create a new key if needed.</li>\\n</ul>\\n<p>For Minio, the <code>accessKeySecret</code> and <code>secretKeySecret</code> naturally correspond the\\nAccessKey and SecretKey.</p>\\n<p>Example:</p>\\n<pre><code>$ kubectl edit configmap workflow-controller-configmap -n argo      # assumes argo was installed in the argo namespace\\n...\\ndata:\\n  config: |\\n    artifactRepository:\\n      s3:\\n        bucket: my-bucket\\n        keyPrefix: prefix/in/bucket     #optional\\n        endpoint: my-minio-endpoint.default:9000        #AWS => s3.amazonaws.com; GCS => storage.googleapis.com\\n        insecure: true                  #omit for S3/GCS. Needed when minio runs without TLS\\n        accessKeySecret:                #omit if accessing via AWS IAM\\n          name: my-minio-cred\\n          key: accessKey\\n        secretKeySecret:                #omit if accessing via AWS IAM\\n          name: my-minio-cred\\n          key: secretKey\\n        useSDKCreds: true               #tells argo to use AWS SDK's default provider chain, enable for things like IRSA support\\n</code></pre>\\n<p>The secrets are retrieved from the namespace you use to run your workflows. Note\\nthat you can specify a <code>keyPrefix</code>.</p>\\n<h2 id=\\\"google-cloud-storage-gcs\\\"><a href=\\\"#google-cloud-storage-gcs\\\" aria-hidden=\\\"true\\\" class=\\\"anchor\\\"><svg aria-hidden=\\\"true\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg></a>Google Cloud Storage (GCS)</h2>\\n<p>Argo also can use native GCS APIs to access a Google Cloud Storage bucket.</p>\\n<p><code>serviceAccountKeySecret</code> refereces to a k8 secret which stores a Google Cloud\\nservice account key to access the bucket.</p>\\n<p>Example:</p>\\n<pre><code>$ kubectl edit configmap workflow-controller-configmap -n argo  # assumes argo was installed in the argo namespace\\n...\\ndata:\\n  config: |\\n    artifactRepository:\\n      gcs:\\n        bucket: my-bucket\\n        keyFormat: prefix/in/bucket     #optional, it could reference workflow variables, such as \\\"{{workflow.name}}/{{pod.name}}\\\"\\n        serviceAccountKeySecret:\\n          name: my-gcs-credentials\\n          key: serviceAccountKey\\n</code></pre>\\n<h1 id=\\\"accessing-non-default-artifact-repositories\\\"><a href=\\\"#accessing-non-default-artifact-repositories\\\" aria-hidden=\\\"true\\\" class=\\\"anchor\\\"><svg aria-hidden=\\\"true\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg></a>Accessing Non-Default Artifact Repositories</h1>\\n<p>This section shows how to access artifacts from non-default artifact\\nrepositories.</p>\\n<p>The <code>endpoint</code>, <code>accessKeySecret</code> and <code>secretKeySecret</code> are the same as for\\nconfiguring the default artifact repository described previously.</p>\\n<pre><code>  templates:\\n  - name: artifact-example\\n    inputs:\\n      artifacts:\\n      - name: my-input-artifact\\n        path: /my-input-artifact\\n        s3:\\n          endpoint: s3.amazonaws.com\\n          bucket: my-aws-bucket-name\\n          key: path/in/bucket/my-input-artifact.tgz\\n          accessKeySecret:\\n            name: my-aws-s3-credentials\\n            key: accessKey\\n          secretKeySecret:\\n            name: my-aws-s3-credentials\\n            key: secretKey\\n    outputs:\\n      artifacts:\\n      - name: my-output-artifact\\n        path: /my-ouput-artifact\\n        s3:\\n          endpoint: storage.googleapis.com\\n          bucket: my-gcs-bucket-name\\n          # NOTE that all output artifacts are automatically tarred and\\n          # gzipped before saving. So as a best practice, .tgz or .tar.gz\\n          # should be incorporated into the key name so the resulting file\\n          # has an accurate file extension.\\n          key: path/in/bucket/my-output-artifact.tgz\\n          accessKeySecret:\\n            name: my-gcs-s3-credentials\\n            key: accessKey\\n          secretKeySecret:\\n            name: my-gcs-s3-credentials\\n            key: secretKey\\n    container:\\n      image: debian:latest\\n      command: [sh, -c]\\n      args: [\\\"cp -r /my-input-artifact /my-output-artifact\\\"]\\n</code></pre>\",\"docPath\":\"argo/configure-artifact-repository\",\"proj\":\"argo\"}}\n\n/***/ })\n\n});\n\n\n// WEBPACK FOOTER //\n// path---docs-argo-configure-artifact-repository-html-fb1534e2ec4258ad8bc0.js","module.exports = {\"pathContext\":{\"docHtml\":\"<h1 id=\\\"configuring-your-artifact-repository\\\"><a href=\\\"#configuring-your-artifact-repository\\\" aria-hidden=\\\"true\\\" class=\\\"anchor\\\"><svg aria-hidden=\\\"true\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg></a>Configuring Your Artifact Repository</h1>\\n<p>To run Argo workflows that use artifacts, you must configure and use an artifact\\nrepository. Argo supports any S3 compatible artifact repository such as AWS, GCS\\nand Minio. This section shows how to configure the artifact repository.\\nSubsequent sections will show how to use it.</p>\\n<h2 id=\\\"configuring-minio\\\"><a href=\\\"#configuring-minio\\\" aria-hidden=\\\"true\\\" class=\\\"anchor\\\"><svg aria-hidden=\\\"true\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg></a>Configuring Minio</h2>\\n<pre><code>$ brew install helm # mac, helm 3.x\\n$ helm repo add stable https://kubernetes-charts.storage.googleapis.com/ # official Helm stable charts\\n$ helm repo update\\n$ helm install argo-artifacts stable/minio --set service.type=LoadBalancer --set fullnameOverride=argo-artifacts\\n</code></pre>\\n<p>Login to the Minio UI using a web browser (port 9000) after obtaining the\\nexternal IP using <code>kubectl</code>.</p>\\n<pre><code>$ kubectl get service argo-artifacts\\n</code></pre>\\n<p>On Minikube:</p>\\n<pre><code>$ minikube service --url argo-artifacts\\n</code></pre>\\n<p>NOTE: When minio is installed via Helm, it uses the following hard-wired default\\ncredentials, which you will use to login to the UI:</p>\\n<ul>\\n<li>AccessKey: AKIAIOSFODNN7EXAMPLE</li>\\n<li>SecretKey: wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY</li>\\n</ul>\\n<p>Create a bucket named <code>my-bucket</code> from the Minio UI.</p>\\n<h2 id=\\\"configuring-aws-s3\\\"><a href=\\\"#configuring-aws-s3\\\" aria-hidden=\\\"true\\\" class=\\\"anchor\\\"><svg aria-hidden=\\\"true\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg></a>Configuring AWS S3</h2>\\n<p>Create your bucket and access keys for the bucket. AWS access keys have the same\\npermissions as the user they are associated with. In particular, you cannot\\ncreate access keys with reduced scope. If you want to limit the permissions for\\nan access key, you will need to create a user with just the permissions you want\\nto associate with the access key. Otherwise, you can just create an access key\\nusing your existing user account.</p>\\n<pre><code>$ export mybucket=bucket249\\n$ cat > policy.json &#x3C;&#x3C;EOF\\n{\\n   \\\"Version\\\":\\\"2012-10-17\\\",\\n   \\\"Statement\\\":[\\n      {\\n         \\\"Effect\\\":\\\"Allow\\\",\\n         \\\"Action\\\":[\\n            \\\"s3:PutObject\\\",\\n            \\\"s3:GetObject\\\"\\n         ],\\n         \\\"Resource\\\":\\\"arn:aws:s3:::$mybucket/*\\\"\\n      }\\n   ]\\n}\\nEOF\\n$ aws s3 mb s3://$mybucket [--region xxx]\\n$ aws iam create-user --user-name $mybucket-user\\n$ aws iam put-user-policy --user-name $mybucket-user --policy-name $mybucket-policy --policy-document file://policy.json\\n$ aws iam create-access-key --user-name $mybucket-user > access-key.json\\n</code></pre>\\n<p>NOTE: if you want argo to figure out which region your buckets belong in, you\\nmust additionally set the following statement policy. Otherwise, you must\\nspecify a bucket region in your workflow configuration.</p>\\n<pre><code>    ...\\n      {\\n         \\\"Effect\\\":\\\"Allow\\\",\\n         \\\"Action\\\":[\\n            \\\"s3:GetBucketLocation\\\"\\n         ],\\n         \\\"Resource\\\":\\\"arn:aws:s3:::*\\\"\\n      }\\n    ...\\n</code></pre>\\n<h2 id=\\\"configuring-gcs-google-cloud-storage\\\"><a href=\\\"#configuring-gcs-google-cloud-storage\\\" aria-hidden=\\\"true\\\" class=\\\"anchor\\\"><svg aria-hidden=\\\"true\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg></a>Configuring GCS (Google Cloud Storage)</h2>\\n<p>Create a bucket from the GCP Console\\n(<a href=\\\"https://console.cloud.google.com/storage/browser\\\">https://console.cloud.google.com/storage/browser</a>).</p>\\n<p>There are 2 ways to configure a Google Cloud Storage.</p>\\n<h3 id=\\\"through-native-gcs-apis\\\"><a href=\\\"#through-native-gcs-apis\\\" aria-hidden=\\\"true\\\" class=\\\"anchor\\\"><svg aria-hidden=\\\"true\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg></a>Through Native GCS APIs</h3>\\n<ul>\\n<li>Create and download a Google Cloud service account key.</li>\\n<li>Create a kubernetes secret to store the key.</li>\\n<li>Configure <code>gcs</code> artifact as following in the yaml.</li>\\n</ul>\\n<pre><code class=\\\"language-yaml\\\">artifacts:\\n  - name: message\\n    path: /tmp/message\\n    gcs:\\n      bucket: my-bucket-name\\n      key: path/in/bucket\\n      # serviceAccountKeySecret is a secret selector.\\n      # It references the k8s secret named 'my-gcs-credentials'.\\n      # This secret is expected to have have the key 'serviceAccountKey',\\n      # containing the base64 encoded credentials\\n      # to the bucket.\\n      #\\n      # If it's running on GKE and Workload Identity is used,\\n      # serviceAccountKeySecret is not needed.\\n      serviceAccountKeySecret:\\n        name: my-gcs-credentials\\n        key: serviceAccountKey\\n</code></pre>\\n<p>If it's a GKE cluster, and Workload Identity is configured, there's no need to\\ncreate the Service Account key and store it as a K8s secret,\\n<code>serviceAccountKeySecret</code> is also not needed in this case. Please follow the\\nlink to configure Workload Identity\\n(<a href=\\\"https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity\\\">https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity</a>).</p>\\n<h3 id=\\\"use-s3-apis\\\"><a href=\\\"#use-s3-apis\\\" aria-hidden=\\\"true\\\" class=\\\"anchor\\\"><svg aria-hidden=\\\"true\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg></a>Use S3 APIs</h3>\\n<p>Enable S3 compatible access and create an access key. Note that S3 compatible\\naccess is on a per project rather than per bucket basis.</p>\\n<ul>\\n<li>Navigate to Storage > Settings\\n(<a href=\\\"https://console.cloud.google.com/storage/settings\\\">https://console.cloud.google.com/storage/settings</a>).</li>\\n<li>Enable interoperability access if needed.</li>\\n<li>Create a new key if needed.</li>\\n<li>Confiture <code>s3</code> artifact as following exmaple.</li>\\n</ul>\\n<pre><code class=\\\"language-yaml\\\">artifacts:\\n  - name: my-output-artifact\\n    path: /my-ouput-artifact\\n    s3:\\n      endpoint: storage.googleapis.com\\n      bucket: my-gcs-bucket-name\\n      # NOTE that all output artifacts are automatically tarred and\\n      # gzipped before saving. So as a best practice, .tgz or .tar.gz\\n      # should be incorporated into the key name so the resulting file\\n      # has an accurate file extension.\\n      key: path/in/bucket/my-output-artifact.tgz\\n      accessKeySecret:\\n        name: my-gcs-s3-credentials\\n        key: accessKey\\n      secretKeySecret:\\n        name: my-gcs-s3-credentials\\n        key: secretKey\\n</code></pre>\\n<h1 id=\\\"configure-the-default-artifact-repository\\\"><a href=\\\"#configure-the-default-artifact-repository\\\" aria-hidden=\\\"true\\\" class=\\\"anchor\\\"><svg aria-hidden=\\\"true\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg></a>Configure the Default Artifact Repository</h1>\\n<p>In order for Argo to use your artifact repository, you can configure it as the\\ndefault repository. Edit the workflow-controller config map with the correct\\nendpoint and access/secret keys for your repository.</p>\\n<h2 id=\\\"s3-compatible-artifact-repository-bucket-such-as-aws-gcs-and-minio\\\"><a href=\\\"#s3-compatible-artifact-repository-bucket-such-as-aws-gcs-and-minio\\\" aria-hidden=\\\"true\\\" class=\\\"anchor\\\"><svg aria-hidden=\\\"true\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg></a>S3 compatible artifact repository bucket (such as AWS, GCS and Minio)</h2>\\n<p>Use the <code>endpoint</code> corresponding to your S3 provider:</p>\\n<ul>\\n<li>AWS: s3.amazonaws.com</li>\\n<li>GCS: storage.googleapis.com</li>\\n<li>Minio: my-minio-endpoint.default:9000</li>\\n</ul>\\n<p>The <code>key</code> is name of the object in the <code>bucket</code> The <code>accessKeySecret</code> and\\n<code>secretKeySecret</code> are secret selectors that reference the specified kubernetes\\nsecret. The secret is expected to have the keys 'accessKey' and 'secretKey',\\ncontaining the base64 encoded credentials to the bucket.</p>\\n<p>For AWS, the <code>accessKeySecret</code> and <code>secretKeySecret</code> correspond to\\nAWS<em>ACCESS</em>KEY<em>ID and AWS</em>SECRET<em>ACCESS</em>KEY respectively.</p>\\n<p>EC2 provides a metadata API via which applications using the AWS SDK may assume\\nIAM roles associated with the instance. If you are running argo on EC2 and the\\ninstance role allows access to your S3 bucket, you can configure the workflow\\nstep pods to assume the role. To do so, simply omit the <code>accessKeySecret</code> and\\n<code>secretKeySecret</code> fields.</p>\\n<p>For GCS, the <code>accessKeySecret</code> and <code>secretKeySecret</code> for S3 compatible access\\ncan be obtained from the GCP Console. Note that S3 compatible access is on a per\\nproject rather than per bucket basis.</p>\\n<ul>\\n<li>Navigate to Storage > Settings\\n(<a href=\\\"https://console.cloud.google.com/storage/settings\\\">https://console.cloud.google.com/storage/settings</a>).</li>\\n<li>Enable interoperability access if needed.</li>\\n<li>Create a new key if needed.</li>\\n</ul>\\n<p>For Minio, the <code>accessKeySecret</code> and <code>secretKeySecret</code> naturally correspond the\\nAccessKey and SecretKey.</p>\\n<p>Example:</p>\\n<pre><code>$ kubectl edit configmap workflow-controller-configmap -n argo      # assumes argo was installed in the argo namespace\\n...\\ndata:\\n  config: |\\n    artifactRepository:\\n      s3:\\n        bucket: my-bucket\\n        keyPrefix: prefix/in/bucket     #optional\\n        endpoint: my-minio-endpoint.default:9000        #AWS => s3.amazonaws.com; GCS => storage.googleapis.com\\n        insecure: true                  #omit for S3/GCS. Needed when minio runs without TLS\\n        accessKeySecret:                #omit if accessing via AWS IAM\\n          name: my-minio-cred\\n          key: accessKey\\n        secretKeySecret:                #omit if accessing via AWS IAM\\n          name: my-minio-cred\\n          key: secretKey\\n        useSDKCreds: true               #tells argo to use AWS SDK's default provider chain, enable for things like IRSA support\\n</code></pre>\\n<p>The secrets are retrieved from the namespace you use to run your workflows. Note\\nthat you can specify a <code>keyPrefix</code>.</p>\\n<h2 id=\\\"google-cloud-storage-gcs\\\"><a href=\\\"#google-cloud-storage-gcs\\\" aria-hidden=\\\"true\\\" class=\\\"anchor\\\"><svg aria-hidden=\\\"true\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg></a>Google Cloud Storage (GCS)</h2>\\n<p>Argo also can use native GCS APIs to access a Google Cloud Storage bucket.</p>\\n<p><code>serviceAccountKeySecret</code> refereces to a k8 secret which stores a Google Cloud\\nservice account key to access the bucket.</p>\\n<p>Example:</p>\\n<pre><code>$ kubectl edit configmap workflow-controller-configmap -n argo  # assumes argo was installed in the argo namespace\\n...\\ndata:\\n  config: |\\n    artifactRepository:\\n      gcs:\\n        bucket: my-bucket\\n        keyFormat: prefix/in/bucket     #optional, it could reference workflow variables, such as \\\"{{workflow.name}}/{{pod.name}}\\\"\\n        serviceAccountKeySecret:\\n          name: my-gcs-credentials\\n          key: serviceAccountKey\\n</code></pre>\\n<h1 id=\\\"accessing-non-default-artifact-repositories\\\"><a href=\\\"#accessing-non-default-artifact-repositories\\\" aria-hidden=\\\"true\\\" class=\\\"anchor\\\"><svg aria-hidden=\\\"true\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg></a>Accessing Non-Default Artifact Repositories</h1>\\n<p>This section shows how to access artifacts from non-default artifact\\nrepositories.</p>\\n<p>The <code>endpoint</code>, <code>accessKeySecret</code> and <code>secretKeySecret</code> are the same as for\\nconfiguring the default artifact repository described previously.</p>\\n<pre><code>  templates:\\n  - name: artifact-example\\n    inputs:\\n      artifacts:\\n      - name: my-input-artifact\\n        path: /my-input-artifact\\n        s3:\\n          endpoint: s3.amazonaws.com\\n          bucket: my-aws-bucket-name\\n          key: path/in/bucket/my-input-artifact.tgz\\n          accessKeySecret:\\n            name: my-aws-s3-credentials\\n            key: accessKey\\n          secretKeySecret:\\n            name: my-aws-s3-credentials\\n            key: secretKey\\n    outputs:\\n      artifacts:\\n      - name: my-output-artifact\\n        path: /my-ouput-artifact\\n        s3:\\n          endpoint: storage.googleapis.com\\n          bucket: my-gcs-bucket-name\\n          # NOTE that all output artifacts are automatically tarred and\\n          # gzipped before saving. So as a best practice, .tgz or .tar.gz\\n          # should be incorporated into the key name so the resulting file\\n          # has an accurate file extension.\\n          key: path/in/bucket/my-output-artifact.tgz\\n          accessKeySecret:\\n            name: my-gcs-s3-credentials\\n            key: accessKey\\n          secretKeySecret:\\n            name: my-gcs-s3-credentials\\n            key: secretKey\\n    container:\\n      image: debian:latest\\n      command: [sh, -c]\\n      args: [\\\"cp -r /my-input-artifact /my-output-artifact\\\"]\\n</code></pre>\",\"docPath\":\"argo/configure-artifact-repository\",\"proj\":\"argo\"}}\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/json-loader!./.cache/json/docs-argo-configure-artifact-repository-html.json\n// module id = 471\n// module chunks = 5458225705137"],"sourceRoot":""}