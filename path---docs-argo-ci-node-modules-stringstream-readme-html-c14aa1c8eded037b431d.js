webpackJsonp([0x82ed516a35f4],{3199:function(e,a){e.exports={pathContext:{docHtml:"<h1>Decode streams into strings The Right Way(tm)</h1>\n<pre><code class=\"language-javascript\">var fs   = require('fs')\nvar zlib = require('zlib')\nvar strs = require('stringstream')\n\nvar utf8Stream = fs.createReadStream('massiveLogFile.gz')\n  .pipe(zlib.createGunzip())\n  .pipe(strs('utf8'))\n</code></pre>\n<p>No need to deal with <code>setEncoding()</code> weirdness, just compose streams\nlike they were supposed to be!</p>\n<p>Handles input and output encoding:</p>\n<pre><code class=\"language-javascript\">// Stream from utf8 to hex to base64... Why not, ay.\nvar hex64Stream = fs.createReadStream('myFile')\n  .pipe(strs('utf8', 'hex'))\n  .pipe(strs('hex', 'base64'))\n</code></pre>\n<p>Also deals with <code>base64</code> output correctly by aligning each emitted data\nchunk so that there are no dangling <code>=</code> characters:</p>\n<pre><code class=\"language-javascript\">var stream = fs.createReadStream('myFile').pipe(strs('base64'))\n\nvar base64Str = ''\n\nstream.on('data', function(data) { base64Str += data })\nstream.on('end', function() {\n  console.log('My base64 encoded file is: ' + base64Str) // Wouldn't work with setEncoding()\n  console.log('Original file is: ' + new Buffer(base64Str, 'base64'))\n})\n</code></pre>",docPath:"argo-ci/node_modules/stringstream/readme",proj:"argo-ci"}}}});
//# sourceMappingURL=path---docs-argo-ci-node-modules-stringstream-readme-html-c14aa1c8eded037b431d.js.map