{"version":3,"sources":["webpack:///path---docs-argo-ci-node-modules-fsevents-node-modules-stringstream-9b8571125ef166f95122.js","webpack:///./.cache/json/docs-argo-ci-node-modules-fsevents-node-modules-stringstream.json"],"names":["webpackJsonp","2591","module","exports","pathContext","docHtml","docPath","proj"],"mappings":"AAAAA,cAAc,iBAERC,KACA,SAAUC,EAAQC,GCHxBD,EAAAC,SAAkBC,aAAeC,QAAA,0uCAAkuCC,QAAA,iEAAAC,KAAA","file":"path---docs-argo-ci-node-modules-fsevents-node-modules-stringstream-9b8571125ef166f95122.js","sourcesContent":["webpackJsonp([197909701348725],{\n\n/***/ 2591:\n/***/ (function(module, exports) {\n\n\tmodule.exports = {\"pathContext\":{\"docHtml\":\"<h1>Decode streams into strings The Right Way(tm)</h1>\\n<pre><code class=\\\"language-javascript\\\">var fs   = require('fs')\\nvar zlib = require('zlib')\\nvar strs = require('stringstream')\\n\\nvar utf8Stream = fs.createReadStream('massiveLogFile.gz')\\n  .pipe(zlib.createGunzip())\\n  .pipe(strs('utf8'))\\n</code></pre>\\n<p>No need to deal with <code>setEncoding()</code> weirdness, just compose streams\\nlike they were supposed to be!</p>\\n<p>Handles input and output encoding:</p>\\n<pre><code class=\\\"language-javascript\\\">// Stream from utf8 to hex to base64... Why not, ay.\\nvar hex64Stream = fs.createReadStream('myFile')\\n  .pipe(strs('utf8', 'hex'))\\n  .pipe(strs('hex', 'base64'))\\n</code></pre>\\n<p>Also deals with <code>base64</code> output correctly by aligning each emitted data\\nchunk so that there are no dangling <code>=</code> characters:</p>\\n<pre><code class=\\\"language-javascript\\\">var stream = fs.createReadStream('myFile').pipe(strs('base64'))\\n\\nvar base64Str = ''\\n\\nstream.on('data', function(data) { base64Str += data })\\nstream.on('end', function() {\\n  console.log('My base64 encoded file is: ' + base64Str) // Wouldn't work with setEncoding()\\n  console.log('Original file is: ' + new Buffer(base64Str, 'base64'))\\n})\\n</code></pre>\",\"docPath\":\"argo-ci/node_modules/fsevents/node_modules/stringstream/readme\",\"proj\":\"argo-ci\"}}\n\n/***/ })\n\n});\n\n\n// WEBPACK FOOTER //\n// path---docs-argo-ci-node-modules-fsevents-node-modules-stringstream-9b8571125ef166f95122.js","module.exports = {\"pathContext\":{\"docHtml\":\"<h1>Decode streams into strings The Right Way(tm)</h1>\\n<pre><code class=\\\"language-javascript\\\">var fs   = require('fs')\\nvar zlib = require('zlib')\\nvar strs = require('stringstream')\\n\\nvar utf8Stream = fs.createReadStream('massiveLogFile.gz')\\n  .pipe(zlib.createGunzip())\\n  .pipe(strs('utf8'))\\n</code></pre>\\n<p>No need to deal with <code>setEncoding()</code> weirdness, just compose streams\\nlike they were supposed to be!</p>\\n<p>Handles input and output encoding:</p>\\n<pre><code class=\\\"language-javascript\\\">// Stream from utf8 to hex to base64... Why not, ay.\\nvar hex64Stream = fs.createReadStream('myFile')\\n  .pipe(strs('utf8', 'hex'))\\n  .pipe(strs('hex', 'base64'))\\n</code></pre>\\n<p>Also deals with <code>base64</code> output correctly by aligning each emitted data\\nchunk so that there are no dangling <code>=</code> characters:</p>\\n<pre><code class=\\\"language-javascript\\\">var stream = fs.createReadStream('myFile').pipe(strs('base64'))\\n\\nvar base64Str = ''\\n\\nstream.on('data', function(data) { base64Str += data })\\nstream.on('end', function() {\\n  console.log('My base64 encoded file is: ' + base64Str) // Wouldn't work with setEncoding()\\n  console.log('Original file is: ' + new Buffer(base64Str, 'base64'))\\n})\\n</code></pre>\",\"docPath\":\"argo-ci/node_modules/fsevents/node_modules/stringstream/readme\",\"proj\":\"argo-ci\"}}\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/json-loader!./.cache/json/docs-argo-ci-node-modules-fsevents-node-modules-stringstream.json\n// module id = 2591\n// module chunks = 197909701348725"],"sourceRoot":""}