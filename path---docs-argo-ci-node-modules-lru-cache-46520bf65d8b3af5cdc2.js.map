{"version":3,"sources":["webpack:///path---docs-argo-ci-node-modules-lru-cache-46520bf65d8b3af5cdc2.js","webpack:///./.cache/json/docs-argo-ci-node-modules-lru-cache.json"],"names":["webpackJsonp","2859","module","exports","pathContext","docHtml","docPath","proj"],"mappings":"AAAAA,cAAc,iBAERC,KACA,SAAUC,EAAQC,GCHxBD,EAAAC,SAAkBC,aAAeC,QAAA,wmMAAwlEC,QAAA,wCAAAC,KAAA","file":"path---docs-argo-ci-node-modules-lru-cache-46520bf65d8b3af5cdc2.js","sourcesContent":["webpackJsonp([249930602227487],{\n\n/***/ 2859:\n/***/ (function(module, exports) {\n\n\tmodule.exports = {\"pathContext\":{\"docHtml\":\"<h1>lru cache</h1>\\n<p>A cache object that deletes the least-recently-used items.</p>\\n<p><a href=\\\"https://travis-ci.org/isaacs/node-lru-cache\\\"><img src=\\\"https://travis-ci.org/isaacs/node-lru-cache.svg?branch=master\\\" alt=\\\"Build Status\\\"></a> <a href=\\\"https://coveralls.io/github/isaacs/node-lru-cache\\\"><img src=\\\"https://coveralls.io/repos/isaacs/node-lru-cache/badge.svg?service=github\\\" alt=\\\"Coverage Status\\\"></a></p>\\n<h2>Installation:</h2>\\n<pre><code class=\\\"language-javascript\\\">npm install lru-cache --save\\n</code></pre>\\n<h2>Usage:</h2>\\n<pre><code class=\\\"language-javascript\\\">var LRU = require(\\\"lru-cache\\\")\\n  , options = { max: 500\\n              , length: function (n, key) { return n * 2 + key.length }\\n              , dispose: function (key, n) { n.close() }\\n              , maxAge: 1000 * 60 * 60 }\\n  , cache = LRU(options)\\n  , otherCache = LRU(50) // sets just the max size\\n\\ncache.set(\\\"key\\\", \\\"value\\\")\\ncache.get(\\\"key\\\") // \\\"value\\\"\\n\\n// non-string keys ARE fully supported\\nvar someObject = {}\\ncache.set(someObject, 'a value')\\ncache.set('[object Object]', 'a different value')\\nassert.equal(cache.get(someObject), 'a value')\\n\\ncache.reset()    // empty the cache\\n</code></pre>\\n<p>If you put more stuff in it, then items will fall out.</p>\\n<p>If you try to put an oversized thing in it, then it'll fall out right\\naway.</p>\\n<h2>Options</h2>\\n<ul>\\n<li><code>max</code> The maximum size of the cache, checked by applying the length\\nfunction to all values in the cache.  Not setting this is kind of\\nsilly, since that's the whole purpose of this lib, but it defaults\\nto <code>Infinity</code>.</li>\\n<li><code>maxAge</code> Maximum age in ms.  Items are not pro-actively pruned out\\nas they age, but if you try to get an item that is too old, it'll\\ndrop it and return undefined instead of giving it to you.</li>\\n<li><code>length</code> Function that is used to calculate the length of stored\\nitems.  If you're storing strings or buffers, then you probably want\\nto do something like <code>function(n, key){return n.length}</code>.  The default is\\n<code>function(){return 1}</code>, which is fine if you want to store <code>max</code>\\nlike-sized things.  The item is passed as the first argument, and\\nthe key is passed as the second argumnet.</li>\\n<li><code>dispose</code> Function that is called on items when they are dropped\\nfrom the cache.  This can be handy if you want to close file\\ndescriptors or do other cleanup tasks when items are no longer\\naccessible.  Called with <code>key, value</code>.  It's called <em>before</em>\\nactually removing the item from the internal cache, so if you want\\nto immediately put it back in, you'll have to do that in a\\n<code>nextTick</code> or <code>setTimeout</code> callback or it won't do anything.</li>\\n<li><code>stale</code> By default, if you set a <code>maxAge</code>, it'll only actually pull\\nstale items out of the cache when you <code>get(key)</code>.  (That is, it's\\nnot pre-emptively doing a <code>setTimeout</code> or anything.)  If you set\\n<code>stale:true</code>, it'll return the stale value before deleting it.  If\\nyou don't set this, then it'll return <code>undefined</code> when you try to\\nget a stale entry, as if it had already been deleted.</li>\\n<li><code>noDisposeOnSet</code> By default, if you set a <code>dispose()</code> method, then\\nit'll be called whenever a <code>set()</code> operation overwrites an existing\\nkey.  If you set this option, <code>dispose()</code> will only be called when a\\nkey falls out of the cache, not when it is overwritten.</li>\\n</ul>\\n<h2>API</h2>\\n<ul>\\n<li>\\n<p><code>set(key, value, maxAge)</code></p>\\n</li>\\n<li>\\n<p><code>get(key) => value</code></p>\\n<p>Both of these will update the \\\"recently used\\\"-ness of the key.\\nThey do what you think. <code>maxAge</code> is optional and overrides the\\ncache <code>maxAge</code> option if provided.</p>\\n<p>If the key is not found, <code>get()</code> will return <code>undefined</code>.</p>\\n<p>The key and val can be any value.</p>\\n</li>\\n<li>\\n<p><code>peek(key)</code></p>\\n<p>Returns the key value (or <code>undefined</code> if not found) without\\nupdating the \\\"recently used\\\"-ness of the key.</p>\\n<p>(If you find yourself using this a lot, you <em>might</em> be using the\\nwrong sort of data structure, but there are some use cases where\\nit's handy.)</p>\\n</li>\\n<li>\\n<p><code>del(key)</code></p>\\n<p>Deletes a key out of the cache.</p>\\n</li>\\n<li>\\n<p><code>reset()</code></p>\\n<p>Clear the cache entirely, throwing away all values.</p>\\n</li>\\n<li>\\n<p><code>has(key)</code></p>\\n<p>Check if a key is in the cache, without updating the recent-ness\\nor deleting it for being stale.</p>\\n</li>\\n<li>\\n<p><code>forEach(function(value,key,cache), [thisp])</code></p>\\n<p>Just like <code>Array.prototype.forEach</code>.  Iterates over all the keys\\nin the cache, in order of recent-ness.  (Ie, more recently used\\nitems are iterated over first.)</p>\\n</li>\\n<li>\\n<p><code>rforEach(function(value,key,cache), [thisp])</code></p>\\n<p>The same as <code>cache.forEach(...)</code> but items are iterated over in\\nreverse order.  (ie, less recently used items are iterated over\\nfirst.)</p>\\n</li>\\n<li>\\n<p><code>keys()</code></p>\\n<p>Return an array of the keys in the cache.</p>\\n</li>\\n<li>\\n<p><code>values()</code></p>\\n<p>Return an array of the values in the cache.</p>\\n</li>\\n<li>\\n<p><code>length</code></p>\\n<p>Return total length of objects in cache taking into account\\n<code>length</code> options function.</p>\\n</li>\\n<li>\\n<p><code>itemCount</code></p>\\n<p>Return total quantity of objects currently in cache. Note, that\\n<code>stale</code> (see options) items are returned as part of this item\\ncount.</p>\\n</li>\\n<li>\\n<p><code>dump()</code></p>\\n<p>Return an array of the cache entries ready for serialization and usage\\nwith 'destinationCache.load(arr)`.</p>\\n</li>\\n<li>\\n<p><code>load(cacheEntriesArray)</code></p>\\n<p>Loads another cache entries array, obtained with <code>sourceCache.dump()</code>,\\ninto the cache. The destination cache is reset before loading new entries</p>\\n</li>\\n<li>\\n<p><code>prune()</code></p>\\n<p>Manually iterates over the entire cache proactively pruning old entries</p>\\n</li>\\n</ul>\",\"docPath\":\"argo-ci/node_modules/lru-cache/readme\",\"proj\":\"argo-ci\"}}\n\n/***/ })\n\n});\n\n\n// WEBPACK FOOTER //\n// path---docs-argo-ci-node-modules-lru-cache-46520bf65d8b3af5cdc2.js","module.exports = {\"pathContext\":{\"docHtml\":\"<h1>lru cache</h1>\\n<p>A cache object that deletes the least-recently-used items.</p>\\n<p><a href=\\\"https://travis-ci.org/isaacs/node-lru-cache\\\"><img src=\\\"https://travis-ci.org/isaacs/node-lru-cache.svg?branch=master\\\" alt=\\\"Build Status\\\"></a> <a href=\\\"https://coveralls.io/github/isaacs/node-lru-cache\\\"><img src=\\\"https://coveralls.io/repos/isaacs/node-lru-cache/badge.svg?service=github\\\" alt=\\\"Coverage Status\\\"></a></p>\\n<h2>Installation:</h2>\\n<pre><code class=\\\"language-javascript\\\">npm install lru-cache --save\\n</code></pre>\\n<h2>Usage:</h2>\\n<pre><code class=\\\"language-javascript\\\">var LRU = require(\\\"lru-cache\\\")\\n  , options = { max: 500\\n              , length: function (n, key) { return n * 2 + key.length }\\n              , dispose: function (key, n) { n.close() }\\n              , maxAge: 1000 * 60 * 60 }\\n  , cache = LRU(options)\\n  , otherCache = LRU(50) // sets just the max size\\n\\ncache.set(\\\"key\\\", \\\"value\\\")\\ncache.get(\\\"key\\\") // \\\"value\\\"\\n\\n// non-string keys ARE fully supported\\nvar someObject = {}\\ncache.set(someObject, 'a value')\\ncache.set('[object Object]', 'a different value')\\nassert.equal(cache.get(someObject), 'a value')\\n\\ncache.reset()    // empty the cache\\n</code></pre>\\n<p>If you put more stuff in it, then items will fall out.</p>\\n<p>If you try to put an oversized thing in it, then it'll fall out right\\naway.</p>\\n<h2>Options</h2>\\n<ul>\\n<li><code>max</code> The maximum size of the cache, checked by applying the length\\nfunction to all values in the cache.  Not setting this is kind of\\nsilly, since that's the whole purpose of this lib, but it defaults\\nto <code>Infinity</code>.</li>\\n<li><code>maxAge</code> Maximum age in ms.  Items are not pro-actively pruned out\\nas they age, but if you try to get an item that is too old, it'll\\ndrop it and return undefined instead of giving it to you.</li>\\n<li><code>length</code> Function that is used to calculate the length of stored\\nitems.  If you're storing strings or buffers, then you probably want\\nto do something like <code>function(n, key){return n.length}</code>.  The default is\\n<code>function(){return 1}</code>, which is fine if you want to store <code>max</code>\\nlike-sized things.  The item is passed as the first argument, and\\nthe key is passed as the second argumnet.</li>\\n<li><code>dispose</code> Function that is called on items when they are dropped\\nfrom the cache.  This can be handy if you want to close file\\ndescriptors or do other cleanup tasks when items are no longer\\naccessible.  Called with <code>key, value</code>.  It's called <em>before</em>\\nactually removing the item from the internal cache, so if you want\\nto immediately put it back in, you'll have to do that in a\\n<code>nextTick</code> or <code>setTimeout</code> callback or it won't do anything.</li>\\n<li><code>stale</code> By default, if you set a <code>maxAge</code>, it'll only actually pull\\nstale items out of the cache when you <code>get(key)</code>.  (That is, it's\\nnot pre-emptively doing a <code>setTimeout</code> or anything.)  If you set\\n<code>stale:true</code>, it'll return the stale value before deleting it.  If\\nyou don't set this, then it'll return <code>undefined</code> when you try to\\nget a stale entry, as if it had already been deleted.</li>\\n<li><code>noDisposeOnSet</code> By default, if you set a <code>dispose()</code> method, then\\nit'll be called whenever a <code>set()</code> operation overwrites an existing\\nkey.  If you set this option, <code>dispose()</code> will only be called when a\\nkey falls out of the cache, not when it is overwritten.</li>\\n</ul>\\n<h2>API</h2>\\n<ul>\\n<li>\\n<p><code>set(key, value, maxAge)</code></p>\\n</li>\\n<li>\\n<p><code>get(key) => value</code></p>\\n<p>Both of these will update the \\\"recently used\\\"-ness of the key.\\nThey do what you think. <code>maxAge</code> is optional and overrides the\\ncache <code>maxAge</code> option if provided.</p>\\n<p>If the key is not found, <code>get()</code> will return <code>undefined</code>.</p>\\n<p>The key and val can be any value.</p>\\n</li>\\n<li>\\n<p><code>peek(key)</code></p>\\n<p>Returns the key value (or <code>undefined</code> if not found) without\\nupdating the \\\"recently used\\\"-ness of the key.</p>\\n<p>(If you find yourself using this a lot, you <em>might</em> be using the\\nwrong sort of data structure, but there are some use cases where\\nit's handy.)</p>\\n</li>\\n<li>\\n<p><code>del(key)</code></p>\\n<p>Deletes a key out of the cache.</p>\\n</li>\\n<li>\\n<p><code>reset()</code></p>\\n<p>Clear the cache entirely, throwing away all values.</p>\\n</li>\\n<li>\\n<p><code>has(key)</code></p>\\n<p>Check if a key is in the cache, without updating the recent-ness\\nor deleting it for being stale.</p>\\n</li>\\n<li>\\n<p><code>forEach(function(value,key,cache), [thisp])</code></p>\\n<p>Just like <code>Array.prototype.forEach</code>.  Iterates over all the keys\\nin the cache, in order of recent-ness.  (Ie, more recently used\\nitems are iterated over first.)</p>\\n</li>\\n<li>\\n<p><code>rforEach(function(value,key,cache), [thisp])</code></p>\\n<p>The same as <code>cache.forEach(...)</code> but items are iterated over in\\nreverse order.  (ie, less recently used items are iterated over\\nfirst.)</p>\\n</li>\\n<li>\\n<p><code>keys()</code></p>\\n<p>Return an array of the keys in the cache.</p>\\n</li>\\n<li>\\n<p><code>values()</code></p>\\n<p>Return an array of the values in the cache.</p>\\n</li>\\n<li>\\n<p><code>length</code></p>\\n<p>Return total length of objects in cache taking into account\\n<code>length</code> options function.</p>\\n</li>\\n<li>\\n<p><code>itemCount</code></p>\\n<p>Return total quantity of objects currently in cache. Note, that\\n<code>stale</code> (see options) items are returned as part of this item\\ncount.</p>\\n</li>\\n<li>\\n<p><code>dump()</code></p>\\n<p>Return an array of the cache entries ready for serialization and usage\\nwith 'destinationCache.load(arr)`.</p>\\n</li>\\n<li>\\n<p><code>load(cacheEntriesArray)</code></p>\\n<p>Loads another cache entries array, obtained with <code>sourceCache.dump()</code>,\\ninto the cache. The destination cache is reset before loading new entries</p>\\n</li>\\n<li>\\n<p><code>prune()</code></p>\\n<p>Manually iterates over the entire cache proactively pruning old entries</p>\\n</li>\\n</ul>\",\"docPath\":\"argo-ci/node_modules/lru-cache/readme\",\"proj\":\"argo-ci\"}}\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/json-loader!./.cache/json/docs-argo-ci-node-modules-lru-cache.json\n// module id = 2859\n// module chunks = 249930602227487"],"sourceRoot":""}